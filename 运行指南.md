# LangSplatV2 项目运行指南

## 项目简介

LangSplatV2 是一个高维3D语言高斯点云项目，能够实现450+ FPS的实时渲染，支持基于文本查询的3D场景理解和分割。

## 一、环境要求

### 硬件要求
- **GPU**: NVIDIA A100（推荐，实验中使用）
- **CUDA**: CUDA SDK 11.8
- **C++编译器**: 用于PyTorch扩展编译

### 软件要求
- **Conda**: 推荐使用Conda进行环境管理
- **Python**: 3.7.13
- **PyTorch**: 1.12.1

## 二、环境搭建

### 1. 克隆仓库（包含子模块）
```bash
# SSH方式
git clone git@github.com:ZhaoYujie2002/LangSplatV2.git --recursive

# 或HTTPS方式
git clone https://github.com/ZhaoYujie2002/LangSplatV2.git --recursive
```

### 2. 创建Conda环境
```bash
conda env create --file environment.yml
conda activate langsplat_v2
```

## 三、数据准备

### 方式1: 使用预处理的公开数据集

项目支持三个公开数据集：

#### LERF数据集
- **下载地址**: [Google Drive](https://drive.google.com/file/d/1QF1Po5p5DwTjFHu6tnTeYs_G0egMVmHt/view?usp=sharing)
- **来源**: [LangSplat仓库](https://github.com/minghanqin/LangSplat)

#### 3D-OVS数据集
- **下载地址**: [Google Drive](https://drive.google.com/drive/folders/1kdV14Gu5nZX6WOPbccG7t7obP_aXkOuC?usp=sharing)
- **来源**: [3D-OVS仓库](https://github.com/Kunhao-Liu/3D-OVS)

#### Mip-NeRF360数据集
- **下载地址**: [Google Drive](https://drive.google.com/drive/folders/1_IbWgVgvnCy4jq9P5EcE6xS44ftcmtgq)
- **来源**: [GAGS仓库](https://github.com/WHU-USI3DV/GAGS)

### 方式2: 使用自己的场景数据

如果使用自己的场景，需要准备以下数据结构：

```
<dataset_name>/
├── images/                    # 输入图像文件夹
│   ├── <image_0>.jpg
│   ├── <image_1>.jpg
│   └── ...
├── output/                    # 预训练的RGB高斯点云模型输出
│   └── <dataset_name>/
│       ├── point_cloud/
│       │   └── iteration_30000/
│       │       └── point_cloud.ply
│       ├── cameras.json
│       ├── cfg_args
│       ├── chkpnt30000.pth    # 预训练checkpoint（必需）
│       └── input.ply
└── sparse/                    # COLMAP稀疏重建结果
    └── 0/
        ├── cameras.bin
        ├── images.bin
        └── points3D.bin
```

**重要说明**：
- 需要先使用 [3D Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting) 训练RGB模型
- 需要COLMAP进行相机位姿估计和稀疏点云重建

## 四、完整运行流程

### Step 1: 预处理 - 生成语言特征

使用OpenCLIP模型为场景图像生成语言特征：

```bash
python preprocess.py --dataset_path <数据集路径>
```

**示例**：
```bash
python preprocess.py --dataset_path ../../data/lerf_ovs/teatime
```

**作用**：
- 使用OpenCLIP（ViT-B-16）提取图像的语言特征
- 使用SAM（Segment Anything Model）进行图像分割
- 生成2D语言特征图，保存为后续训练使用

**输出**：
- 在数据集目录下生成语言特征文件（通常为`.pth`或`.npy`格式）

### Step 2: 训练 - 训练全局语义码本和稀疏系数场

训练过程会为3个不同的特征层级（level 1, 2, 3）分别训练模型：

```bash
bash train.sh <数据集根路径> <场景名称> <模型索引>
```

**示例**：
```bash
bash train.sh ../../data/lerf_ovs teatime 0
```

**参数说明**：
- `数据集根路径`: 包含所有场景的根目录
- `场景名称`: 具体场景名称（如`teatime`）
- `模型索引`: 模型版本索引（如`0`）

**训练配置**（在`train.sh`中）：
- `TOPK=4`: Top-K检索数量
- `feature_level`: 特征层级（1, 2, 3）
- `vq_layer_num=1`: 向量量化层数
- `codebook_size=64`: 码本大小
- `cos_loss`: 使用余弦损失

**输出**：
- 训练好的checkpoint保存在：`output/<场景名称>_<索引>_{1,2,3}/chkpnt<迭代次数>.pth`
- 每个level会生成独立的模型

### Step 3: 评估/推理

根据不同的数据集类型，使用不同的评估脚本：

#### 3.1 LERF数据集评估

```bash
bash eval_lerf.sh <场景名称> <模型索引> <checkpoint迭代次数>
```

**示例**：
```bash
bash eval_lerf.sh teatime 0 10000
```

**参数说明**：
- `场景名称`: 如`teatime`
- `模型索引`: 如`0`
- `checkpoint迭代次数`: 如`10000`

**输出**：
- 评估结果保存在：`eval_result/<场景名称>_<索引>/`
- 包含分割mask、相关性热力图等

#### 3.2 3D-OVS数据集评估

```bash
bash eval_3d_ovs.sh <场景名称> <模型索引> <checkpoint迭代次数>
```

**示例**：
```bash
bash eval_3d_ovs.sh <scene_name> 0 10000
```

#### 3.3 Mip-NeRF360数据集评估

```bash
bash eval_mip_nerf360.sh <场景名称> <模型索引> <checkpoint迭代次数>
```

### Step 4: 可视化（可选）

使用可视化脚本查看查询结果：

```bash
bash visualize_lerf.sh <场景名称> <模型索引> <checkpoint> <查询文本> <视图索引>
```

**示例**：
```bash
bash visualize_lerf.sh teatime 0 10000 "teapot" 0
```

**输出结果**（保存在`visualize_result/`目录）：
1. **rgb.png**: 渲染的RGB图像
2. **heatmap.png**: 查询相关性热力图（使用turbo colormap）
3. **overlay.png**: RGB图像与热力图的叠加（半透明）
4. **mask.png**: 二值化分割mask（阈值=0.4）
5. **mask_overlay.png**: RGB图像与分割mask的叠加

## 五、快速开始（使用预训练模型）

如果已经下载了预训练模型权重：

1. 将模型权重放到 `output/` 目录下
2. 直接运行评估脚本：

```bash
# LERF数据集
bash eval_lerf.sh teatime 0 10000
```

## 六、输出结果说明

### 训练阶段输出
- **Checkpoint文件**: `output/<场景名>_<索引>_{1,2,3}/chkpnt<迭代次数>.pth`
  - 包含3个level的模型权重
  - 每个level对应不同分辨率的特征表示

### 评估阶段输出
- **分割结果**: 基于文本查询的3D场景分割mask
- **相关性图**: 查询文本与场景区域的相关性热力图
- **评估指标**: mIoU、准确率等（根据数据集类型）

### 可视化输出
- **RGB渲染**: 场景的RGB图像
- **热力图**: 文本查询的相关性可视化
- **分割mask**: 二值化的分割结果
- **叠加图像**: 各种可视化结果的组合

## 七、常见问题

### 1. 数据路径问题
- 确保数据集路径结构符合要求
- 检查`chkpnt30000.pth`是否存在（RGB预训练模型）

### 2. Checkpoint路径问题
- 确保3个level的checkpoint都存在
- 路径格式：`output/<场景名>_<索引>_{1,2,3}/chkpnt<迭代次数>.pth`

### 3. GPU显存不足
- 减少batch size
- 使用`--quick_render`参数
- 降低图像分辨率

### 4. 依赖安装问题
- 确保子模块正确安装：`submodules/segment-anything-langsplat`、`submodules/efficient-langsplat-rasterization`、`submodules/simple-knn`
- 检查CUDA版本兼容性

## 八、项目结构说明

```
LangSplatV2/
├── preprocess.py          # 预处理脚本（生成语言特征）
├── train.py               # 训练脚本
├── eval_lerf.py          # LERF数据集评估
├── eval_3d_ovs.py        # 3D-OVS数据集评估
├── eval_mip_nerf360.py   # Mip-NeRF360数据集评估
├── visualize_lerf.py     # 可视化脚本
├── scene/                # 场景相关代码
│   ├── gaussian_model.py # 高斯点云模型
│   └── cameras.py        # 相机处理
├── gaussian_renderer/    # 渲染器
├── eval/                 # 评估工具
│   ├── openclip_encoder.py  # OpenCLIP编码器
│   └── utils.py
└── utils/                # 工具函数
    ├── vq_utils.py       # 向量量化工具
    └── loss_utils.py     # 损失函数
```

## 九、技术要点

1. **多层级特征**: 使用3个不同level的特征表示，实现多尺度语义理解
2. **向量量化**: 使用Residual Vector Quantization (RVQ) 压缩高维语言特征
3. **快速渲染**: 优化的渲染管线实现450+ FPS的实时渲染
4. **文本查询**: 支持自然语言文本查询3D场景中的物体

## 十、参考资料

- **论文**: [arXiv:2507.07136](https://arxiv.org/abs/2507.07136)
- **项目主页**: [LangSplatV2](https://langsplat-v2.github.io/)
- **模型权重**: [Google Drive](https://drive.google.com/drive/folders/1bHzv8e69NHseEj-3Qe0k0GqTmDYMGg-K?usp=sharing)

